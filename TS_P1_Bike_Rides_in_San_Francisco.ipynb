{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Pilot Project: Bike Rides in San Francisco\n",
        "\n",
        "\n",
        "###**Case Study:** Analyzing & Forecasting the number of bike rides in San Francisco\n",
        "**Objective:** The goal of this challenge is to let you dive deep into time-series signals, analyze it and determine the best predictive model.\n",
        "The challenge is divided into 2 parts:\n",
        "\n",
        "* **Part A:** Use time-series data of the number of bike rides in San Francisco and analyze it to better understand it and choose one of the statistical models to predict future values.\n",
        "\n",
        "\n",
        "* **Part B:** Prepare the same data and structure it in order to train an RNN to predict the number of bike rides for the next 7 days.\n",
        "\n"
      ],
      "metadata": {
        "id": "1b7n_u6cwBKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Part A: Time-series analysis and forecasting\n",
        "\n"
      ],
      "metadata": {
        "id": "7iR3QyKkzAKo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-series Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "1-aH5B1_zZ-9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Importing the libraries\n"
      ],
      "metadata": {
        "id": "M_LXNvQK0OvW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from statsmodels.graphics.tsaplots import plot_acf\n",
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "from statistics import mean\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.stats.diagnostic import acorr_ljungbox\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "xFb7Fl4O0jO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Loading & Visualization\n"
      ],
      "metadata": {
        "id": "MOkoZfVozr0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset\n",
        "bike_rides_df = pd.read_csv('/content/Bike Rides aggregated.csv')\n",
        "#convert dtype of date col to be datetime\n",
        "bike_rides_df['date'] = pd.to_datetime(bike_rides_df['date'])\n",
        "#set the index of dataframe to be date col\n",
        "bike_rides_df.set_index('date', inplace=True)"
      ],
      "metadata": {
        "id": "pYq0aJUc2IWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gM-fH2hLv5Bg"
      },
      "outputs": [],
      "source": [
        "# Plotting\n",
        "bike_rides_df.plot()\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Bikes')\n",
        "plt.title('Number of Bike Rides Over Time')\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above plot, the number of bike rides is maximum during July and October 2018 and minimum during January 2018."
      ],
      "metadata": {
        "id": "dQuUG_Sj04_-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#display the first five rows of the dataframe\n",
        "bike_rides_df.head()"
      ],
      "metadata": {
        "id": "YveIFU7RYAqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bike_rides_df.shape\n",
        "print(f'The dataset has {bike_rides_df.shape[0]} rows and {bike_rides_df.shape[1]} columns.')"
      ],
      "metadata": {
        "id": "8YATIxOVYIB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Decomposition\n",
        "The statsmodels library provides an implementation of the decomposition method in a function called seasonal_decompose(). Use it to decompose your data and specify the model to be additive.\n",
        "\n"
      ],
      "metadata": {
        "id": "qACP6hy81CH9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decomposition = seasonal_decompose(bike_rides_df['bike_numbers'], model='additive')\n",
        "decomposition.plot()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ChYkP2L71eLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   **The trend component in the data is not stable and does not evolve in a consistent manner. Specifically, the trend component exhibits an upward movement over time, peaking around mid-to-late 2018, followed by a decline beginning in November 2018. This pattern suggests that bike usage could be influenced by external factors, such as seasonal weather conditions or other environmental variables.**\n",
        "\n",
        "*   **In the seasonality component, we observe repeated patterns on a weekly basis. The frequent repetitions suggest a shorter periodicity than monthly indicating a seasonal effect tied to weekly cycles.**\n",
        "\n",
        "*   **In the residual component, noise and short-term fluctuations  are not systematic and unpredictable.**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NPgNuBIKIrML"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Autocorrelation\n",
        "To better understand time-series, we need to study its autocorrelation which gives us an idea on how lags are affecting current/future values.\n"
      ],
      "metadata": {
        "id": "hCt-auwW3yfh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  a 1-row, 3-column figure\n",
        "fig, axs = plt.subplots(1, 3, figsize=(18, 5))\n",
        "\n",
        "# Plot ACF for different lags in each subplot\n",
        "plot_acf(bike_rides_df['bike_numbers'], lags=25, ax=axs[0])\n",
        "axs[0].set_title(\"ACF with 25 Lags\")\n",
        "\n",
        "plot_acf(bike_rides_df['bike_numbers'], lags=30, ax=axs[1])\n",
        "axs[1].set_title(\"ACF with 30 Lags\")\n",
        "\n",
        "plot_acf(bike_rides_df['bike_numbers'], lags=45, ax=axs[2])\n",
        "axs[2].set_title(\"ACF with 45 Lags\")\n",
        "\n",
        "# Adjust layout to prevent overlap\n",
        "plt.tight_layout()\n",
        "\n",
        "# Show the figure\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uFYK6KM34OK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note:** Since the time series exhibits weekly seasonality, I used 25 lags to cover 25 days, 30 lags to represent a month, and 45 lags to cover 45 days (a month and 15 days). These values were chosen to analyze the data from a broader perspective. Additionally, 14 lags can be used to cover two seasonal cycles. Therefore, the selection of lags was guided by the observed seasonality patterns."
      ],
      "metadata": {
        "id": "njOVw5SWaqyg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The ACF plots reveal strong evidence of seasonality in the time series. This is supported by the presence of a sinusoidal pattern across multiple lags and the observation of significant spikes at regular intervals (lags 7, 14, 21, etc.), suggesting a weekly seasonal cycle. Furthermore, the autocorrelation values remain significantly above the confidence threshold for numerous lags, indicating a strong autocorrelation structure within the time series.**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fdd3zlR4IvxC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Partial Autocorrelation\n",
        "To better understand time series, we need to study its partial autocorrelation, which gives us an idea of how lags affect current/future values without having the in-between-lags effect.\n"
      ],
      "metadata": {
        "id": "2Af1sohHLf6r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.graphics.tsaplots import plot_pacf\n",
        "\n",
        "plot_pacf(bike_rides_df['bike_numbers'], lags=25)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "eRc4vtcM5W0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the above PACF plot,**\n",
        "\n",
        "\n",
        "*   **The first lag has a strong positive correlation, indicating that the previous time step is a good predictor of the current value.**\n",
        "*   **The presence of several significant lags suggests a higher-order AR process.**\n",
        "\n",
        "\n",
        "*   **After around lag 10, the correlations drop within the confidence interval, implying that the direct influence weakens beyond this point.**\n",
        "*   **The presence of negative values at some lags suggests possible oscillations in the data.**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0qG29IsQ7jSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Ljung-Box Q-test\n",
        "ljung_box_results = acorr_ljungbox(bike_rides_df['bike_numbers'], lags=[7, 14, 21], return_df=True)\n",
        "\n",
        "# Display the test results\n",
        "print(\"Ljung-Box Q-Test Results:\")\n",
        "print(ljung_box_results)\n"
      ],
      "metadata": {
        "id": "Zxg-u8lX__2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I applied the Ljung-Box Q-test, a statistical method used to detect autocorrelation in a time series at various lags. Since the p-value is less than 0.05, we reject the null hypothesis, indicating that the data is not random and the selected lags show significant autocorrelation.**"
      ],
      "metadata": {
        "id": "ZMEjfxVJBP30"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check TS for Stationarity"
      ],
      "metadata": {
        "id": "K8yAFztSaLJR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.stattools import adfuller\n",
        "\n",
        "# Perform the ADF test to check if the bike_rides_df  is stationary\n",
        "#Check stationarity\n",
        "result = adfuller(bike_rides_df['bike_numbers'])\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "\n",
        "\n",
        "\n",
        "# Interpretation\n",
        "if result[1] < 0.05:\n",
        "    print(\"Reject the null hypothesis: The time series is stationary.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The time series is non-stationary.\")\n"
      ],
      "metadata": {
        "id": "RK5e1wX_Ztcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the above ADF test, the time series is non-stationary."
      ],
      "metadata": {
        "id": "49U1NFGrbzQx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time-series Forecasting\n",
        "The goal of this section is to use the previous analysis to determine which of the statistical models you learned through the week.\n",
        "\n"
      ],
      "metadata": {
        "id": "W1U-b2IX5tXX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Simple moving average"
      ],
      "metadata": {
        "id": "bi9LGE0aFhR0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Applying a simple moving average filter on the data with a window of size 20."
      ],
      "metadata": {
        "id": "8e0iuW6nEdl3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying a moving average filter with window size of 20 to a copy of the original data frame\n",
        "avg_bike_rides_df= bike_rides_df.rolling(window=20).mean()\n",
        "#displaying the dataset\n",
        "avg_bike_rides_df.plot()\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Bikes')\n",
        "plt.title('Number of Bike Rides Over Time')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mnQlgX88EjBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "avg_bike_rides_df.head(30)"
      ],
      "metadata": {
        "id": "ifKbLN_j-_Hx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In the above dataset (avg_bike_rides_df), we notice that the first 19 rows are NAN because we applied the moving average with window size of 20.**"
      ],
      "metadata": {
        "id": "1R-Y5e9Xf42-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bike_rides_df.shape"
      ],
      "metadata": {
        "id": "yhAHztBxDEr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the original dataset (bike_rides_df) and the averaged dataset (avg_bike_rides_df)\n",
        "plt.plot(bike_rides_df, label='Original Data')\n",
        "plt.plot(avg_bike_rides_df, label='Averaged Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "qoJaXAtnCfov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The plot above shows the original time series data alongside the time series after applying the simple moving average filter. It is evident that the resulting time series has been smoothed.**"
      ],
      "metadata": {
        "id": "m93gR8hJhT6D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To better see the effect of the moving average filter:\n",
        "- I'll set the first 400 days for training and the rest for testing\n",
        "-  copy the dataframe and add a column to the predicted value with window size of 2"
      ],
      "metadata": {
        "id": "JXiCXGwXE8fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# select the first 400 observations for training\n",
        "train_len = 400\n",
        "train_data = bike_rides_df[0:train_len] # first 400 days as training set.\n",
        "test_data = bike_rides_df[train_len:] # last 552-400 days as out-of-time test set.\n",
        "\n",
        "# copy the dataframe and add a column to the predicted value with window size of 2\n",
        "sma_bike_rides_df =bike_rides_df.copy()\n",
        "ma_window = 2\n",
        "sma_bike_rides_df['sma_forecast'] = bike_rides_df['bike_numbers'].rolling(ma_window).mean()\n"
      ],
      "metadata": {
        "id": "rWyu2PcZFU2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's plot the training, testing data, and the predictions made by the simple moving average on the same graph."
      ],
      "metadata": {
        "id": "pbaJSFYJFfDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20,5))\n",
        "plt.grid()\n",
        "plt.plot(train_data['bike_numbers'], label='Train')\n",
        "plt.plot(test_data['bike_numbers'], label='Test')\n",
        "plt.plot(sma_bike_rides_df['sma_forecast'], label='Simple moving average forecast')\n",
        "plt.legend(loc='best')\n",
        "plt.title('Simple Moving Average Method')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4wN2l4MOFlns"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The above plot shows the training and testing sets along with the Simple Moving Average (SMA) forecast applied to the dataset. The SMA method effectively smooths the data, reducing short-term fluctuations and capturing the general trend. However, due to its lagging nature, it may struggle to accurately predict sharp changes or seasonal variations in the data.**"
      ],
      "metadata": {
        "id": "mHhF4iXYM3A6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Calculating the RMSE (Root Mean Squared Error)"
      ],
      "metadata": {
        "id": "mN2FqU5ROsXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the sma_forecast column of sma_bike_rides_df after applying a moving average with a window size of 2.\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#calculate the rmse\n",
        "rmse = sqrt(mean_squared_error(test_data, sma_bike_rides_df['sma_forecast'][train_len:]))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "metadata": {
        "id": "0D8Dh1aKHvze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluating the bike_numbers column of avg_bike_rides_df after applying a moving average with a window size of 20.\n",
        "from math import sqrt\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#calculate the rmse\n",
        "rmse = sqrt(mean_squared_error(test_data, avg_bike_rides_df['bike_numbers'][train_len:]))\n",
        "print('Test RMSE: %.3f' % rmse)"
      ],
      "metadata": {
        "id": "ToyC_BE0Jcpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the RMSE metric, the moving average with a window size of 2 provides better predictions than the one with a window size of 20, as it has a lower RMSE.**"
      ],
      "metadata": {
        "id": "QFl7EmrsMU4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical models"
      ],
      "metadata": {
        "id": "VyJFmNWM3lM-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#split the dataset into 2 partitions\n",
        "split = round(len(bike_rides_df) / 2)\n",
        "X1, X2 = bike_rides_df[0:split], bike_rides_df[split:]\n",
        "#calculate each partitions' mean and variance\n",
        "mean1, mean2 = X1.mean(), X2.mean()\n",
        "var1, var2 = X1.var(), X2.var()\n",
        "print('mean1=%f, mean2=%f' % (mean1, mean2))\n",
        "print('variance1=%f, variance2=%f' % (var1, var2))"
      ],
      "metadata": {
        "id": "F9TtcBgPPj7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the above, we split the dataset into two partitions and calculated their mean and variance. Since the mean of X1 (partition 1) differs from the mean of X2 (partition 2) and variance of X1 (partition 1) differ from the variance of X2 (partition 2) , we conclude that the time series is non-stationary.**"
      ],
      "metadata": {
        "id": "nfi6zfKfQLJc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the ADF test to check if the bike_rides_df is stationary\n",
        "result = adfuller(bike_rides_df['bike_numbers'])  # Apply to your time series column\n",
        "print('ADF Statistic:', result[0])\n",
        "print('p-value:', result[1])\n",
        "print('Critical Values:', result[4])\n",
        "\n",
        "# Interpretation\n",
        "if result[1] < 0.05:\n",
        "    print(\"Reject the null hypothesis: The time series is stationary.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The time series is non-stationary.\")\n"
      ],
      "metadata": {
        "id": "ZdZ4_UWOFyFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the Augmented Dickey-Fuller (ADF) Test, the time series is non-stationary since the p-value > 0.05 null hypothesis is rejected.**\n",
        "\n",
        "**Since the mean of X1 (partition 1) differs from the mean of X2 (partition 2) and variance of X1 (partition 1) differ from the variance of X2 (partition 2) differ, we conclude that the time series is non-stationary.**"
      ],
      "metadata": {
        "id": "2N0LdgXJI4Ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Differencing"
      ],
      "metadata": {
        "id": "R3f9c_5G3h5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Perform differencing to make data stationary\n",
        "diff = bike_rides_df.diff()\n",
        "diff.plot()"
      ],
      "metadata": {
        "id": "zzFb2SpcIuUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.info()"
      ],
      "metadata": {
        "id": "sq_hWg2YT7Im"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.isnull().sum()"
      ],
      "metadata": {
        "id": "tOdGyK_FWMtK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.dropna(inplace=True)"
      ],
      "metadata": {
        "id": "8JGxJuJeWYLN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.isnull().sum()"
      ],
      "metadata": {
        "id": "Td8WNFW8WcEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "diff.info()"
      ],
      "metadata": {
        "id": "ENf08pMYWf8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform the ADF test to check if the diff (result of performing differencing on bike_rides_df) is stationary\n",
        "#Check stationarity\n",
        "result = adfuller(diff['bike_numbers'])\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "\n",
        "\n",
        "\n",
        "# Interpretation\n",
        "if result[1] < 0.05:\n",
        "    print(\"Reject the null hypothesis: The time series is stationary.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The time series is non-stationary.\")\n"
      ],
      "metadata": {
        "id": "17SPYA2qTXOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plotting differenced data ,acf and pacf plots after applying differencing\n",
        "\n",
        "fig, axes = plt.subplots(nrows=3, ncols=1,\n",
        "                         sharex= False, sharey=False, figsize=(10, 10))\n",
        "ax = axes.ravel()\n",
        "ax[0].plot(diff)\n",
        "ax[0].set_title('Original data')\n",
        "\n",
        "fig = plot_acf(x=diff, lags=25,ax=ax[1])\n",
        "ax[1].set_title('Autocorrelation')\n",
        "\n",
        "fig = plot_pacf(diff, lags=25,ax=ax[2])\n",
        "ax[2].set_title('Partial Autocorrelation')"
      ],
      "metadata": {
        "id": "AIuEe1y5YEXM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Square Root Transformation and Differencing"
      ],
      "metadata": {
        "id": "N6GHgLBdNXns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply square root transformation\n",
        "sqrt_bike_rides_df= np.sqrt(bike_rides_df)\n",
        "# Apply differencing and drop Nan values\n",
        "sqrt_bike_rides_df= sqrt_bike_rides_df.diff().dropna()\n"
      ],
      "metadata": {
        "id": "c47P5knsNeY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot the sqrt_bike_rides_df\n",
        "sqrt_bike_rides_df.plot()\n",
        "plt.tight_layout()  # Adjust layout to prevent overlap\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Number of Bikes')\n",
        "plt.title('Number of Bike Rides Over Time after applying Square Root Transformation and Differencing')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hbjUrJ24Qd--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply adf test\n",
        "result = adfuller(sqrt_bike_rides_df['bike_numbers'])\n",
        "print('ADF Statistic: %f' % result[0])\n",
        "print('p-value: %f' % result[1])\n",
        "\n",
        "# Interpretation\n",
        "if result[1] < 0.05:\n",
        "    print(\"Reject the null hypothesis: The time series is stationary.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The time series is non-stationary.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "roc2dBa8Txb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#plot the ACF and PACF plots for sqrt_bike_rides_df (resulted dataset of applying square root transfromation then differencing)\n",
        "fig, axes = plt.subplots(nrows=2, ncols=1,\n",
        "                         sharex= False, sharey=False, figsize=(10, 10))\n",
        "ax = axes.ravel()\n",
        "fig = plot_acf(x=sqrt_bike_rides_df, lags=25,ax=ax[0])\n",
        "ax[0].set_title('Autocorrelation')\n",
        "\n",
        "fig = plot_pacf(sqrt_bike_rides_df, lags=25,ax=ax[1])\n",
        "ax[1].set_title('Partial Autocorrelation')"
      ],
      "metadata": {
        "id": "fZKCcbi-TSC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Split the sqrt_bike_rides_df (resulted dataset of applying square root transformation then differencing) into train and test sets"
      ],
      "metadata": {
        "id": "0Alig5tHXiZt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_len = 400\n",
        "train_sqrt_bike_rides_df = sqrt_bike_rides_df[0:train_len] # first 400 days as training set.\n",
        "test_sqrt_bike_rides_df = sqrt_bike_rides_df[train_len:] # last 151 days as  test set."
      ],
      "metadata": {
        "id": "0-lmiarRYdae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Apply Statistical Modeling"
      ],
      "metadata": {
        "id": "FDblXM7_YtlZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 uninstall statsmodels -y\n",
        "!pip3 install numpy scipy patsy pandas\n",
        "!pip3 install statsmodels\n"
      ],
      "metadata": {
        "id": "ibnAco0tJ0zH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###AR Model Order of 20"
      ],
      "metadata": {
        "id": "K0p_h3yuZfxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.ar_model import AutoReg\n",
        "#apply Auto Regressive model\n",
        "# train the model\n",
        "ARmodel = AutoReg(train_sqrt_bike_rides_df, lags =20).fit()\n",
        "\n",
        "# Use the model to make predictions on the test data and evaluate it\n",
        "ARpred = ARmodel.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_ar = sqrt(mean_squared_error(test_sqrt_bike_rides_df, ARpred))\n",
        "print('Test RMSE: %.3f' % rmse_ar)"
      ],
      "metadata": {
        "id": "GgB_dsGSYAK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Test actual values against AR Model of order(20) predictions"
      ],
      "metadata": {
        "id": "luY_9AYIg7Hn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ARpred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kgrYoqWmhJGs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the above plot, there is a significant gap between actual values and the predicted values**"
      ],
      "metadata": {
        "id": "OwTdsP5HiNbC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SARIMAX model with order (0,0,2), it primarily represents a Moving Average (MA) model"
      ],
      "metadata": {
        "id": "WoJG-kw2letD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAmodel = SARIMAX(train_sqrt_bike_rides_df, order = (0,0,7)).fit()\n",
        "MApred = MAmodel.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_ma = sqrt(mean_squared_error(test_sqrt_bike_rides_df, MApred))\n",
        "print('Test RMSE: %.3f' % rmse_ma)"
      ],
      "metadata": {
        "id": "vxLSUWDMjwMj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Test actual values against MA Model of order(7) predictions"
      ],
      "metadata": {
        "id": "_H_xe16GntD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(MApred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "K_xUDzKTkz0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the RMSE and the above plot, I deduced that moving average model is not the right approach for this time series data.**"
      ],
      "metadata": {
        "id": "jWgpV56KkeH6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SARIMAX model with order (20,0,7), it primarily represents an ARMA Model"
      ],
      "metadata": {
        "id": "w3JGWTX6q-hB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ARMA Model of (20,0,7) p= 20, d= 0, q= 7\n",
        "ARMAmodel = SARIMAX(train_sqrt_bike_rides_df, order = (20,0,7)).fit()\n",
        "ARMApred = ARMAmodel.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_arma = sqrt(mean_squared_error(test_sqrt_bike_rides_df, ARMApred))\n",
        "print('Test RMSE: %.3f' % rmse_arma)"
      ],
      "metadata": {
        "id": "GG3H6PFKpKgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plotting Test actual values against ARMA Model (20,0,7) predictions"
      ],
      "metadata": {
        "id": "Y4raizbYrG_q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ARMApred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OHPvu9fQq8Sm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SARIMAX MODEL of order (20,2,7), primarily representing ARIMA Model."
      ],
      "metadata": {
        "id": "sJzeNPS4PSZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ARMAmodel\n",
        "ARIMAmodel = SARIMAX(train_sqrt_bike_rides_df, order = (20, 2, 7))\n",
        "# train the model\n",
        "ARIMAmodel = ARIMAmodel.fit()\n",
        "\n",
        "# Use the model to make predictions on the test data and evaluate it\n",
        "ARIMApred = ARIMAmodel.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_arima = sqrt(mean_squared_error(test_sqrt_bike_rides_df, ARIMApred))\n",
        "print('Test RMSE: %.3f' % rmse_arima)"
      ],
      "metadata": {
        "id": "MY3Y2TX6ZSyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(ARIMApred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "84XC7NMSbkFF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SARIMAX model with 2 options"
      ],
      "metadata": {
        "id": "fX4GJN5PhJAC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nonseasonal components (for nonseasonal part of the model) order(1,1,2) and the  seasonal components (for the seasonal part of the model) order (20,1,7,7) which represent (p,d,q,s) s stands for seasonal suspecting a weekly seasonality."
      ],
      "metadata": {
        "id": "q8WTzEg4h2CG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Define the model\n",
        "model = SARIMAX(train_sqrt_bike_rides_df,\n",
        "                order=(1,1,2),\n",
        "                seasonal_order=(20,1,7,7))\n",
        "\n",
        "# Fit the model\n",
        "results = model.fit()\n",
        "\n",
        "# Summary of the model\n",
        "print(results.summary())\n",
        "\n",
        "# Plot predictions\n",
        "modelPred = results.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_model = sqrt(mean_squared_error(test_sqrt_bike_rides_df, modelPred))\n",
        "print('Test RMSE: %.3f' % rmse_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "_gOAcbqTQMpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(modelPred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2SBecpTEZcsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##SARIMAX model with 2 options"
      ],
      "metadata": {
        "id": "yGJ7dURtiFLu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Nonseasonal components (for nonseasonal part of the model) order(1,1,2) and the  seasonal components (for the seasonal part of the model) order (2,1,2,7) which represent (p,d,q,s) s stands for seasonal suspecting a weekly seasonality"
      ],
      "metadata": {
        "id": "941zX-e0iHrN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "# Define the model\n",
        "model = SARIMAX(train_sqrt_bike_rides_df,\n",
        "                order=(1,1,2),\n",
        "                seasonal_order=(2,1,2,7))\n",
        "\n",
        "# Fit the model\n",
        "results = model.fit()\n",
        "\n",
        "# Summary of the model\n",
        "print(results.summary())\n",
        "\n",
        "# Plot predictions\n",
        "modelPred = results.predict(start=test_sqrt_bike_rides_df.index.min(), end=test_sqrt_bike_rides_df.index.max())\n",
        "\n",
        "rmse_model = sqrt(mean_squared_error(test_sqrt_bike_rides_df, modelPred))\n",
        "print('Test RMSE: %.3f' % rmse_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "uwwVuZr2ecmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(modelPred, linestyle='--', marker='o', label='Predictions')\n",
        "plt.plot(test_sqrt_bike_rides_df, linestyle='--', marker='o', label='Test Data')\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2R_m4oPlgg9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**It is evident in the above plot that the residuals and the gaps decreased between some actual values and predicted values.**"
      ],
      "metadata": {
        "id": "DlIYduEImpRn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**I tried all statistical models yet none of these models was good at simulating the behavior of this dataset.This may be caused by several reasons:**\n",
        "\n",
        "\n",
        "*   **Data may be not having a certain pattern that can be simulated with some statistical models.**\n",
        "\n"
      ],
      "metadata": {
        "id": "POKyeD0eQOqD"
      }
    }
  ]
}